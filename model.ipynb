{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the tiny shakespeare dataset\n",
    "input_file_path = 'shakespeare.txt'\n",
    "if not os.path.exists(input_file_path):\n",
    "    data_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "    with open(input_file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(requests.get(data_url).text)\n",
    "\n",
    "with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "    data = f.read()\n",
    "n = len(data)\n",
    "train_data = data[:int(n*0.9)]\n",
    "val_data = data[int(n*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch: i for i, ch in enumerate(sorted(set(data)))}\n",
    "itos = {i: ch for ch, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_encoded = np.array([stoi[ch] for ch in train_data], dtype=np.uint16)\n",
    "val_data_encoded = np.array([stoi[ch] for ch in val_data], dtype=np.uint16)\n",
    "def encode(s):\n",
    "    return [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "def decode(l):\n",
    "    return ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(stoi)\n",
    "n_embd = 32\n",
    "batch_size = 640\n",
    "block_size = 8\n",
    "head_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    if split == 'train':\n",
    "        data = train_data_encoded\n",
    "    elif split == 'val':\n",
    "        data = val_data_encoded\n",
    "    else:\n",
    "        raise ValueError('split must be either train or val')\n",
    "    start_idx = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in start_idx])\n",
    "    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in start_idx])\n",
    "    return x.to(device), y.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[27, 27, 28,  ..., 25, 43, 52],\n",
       "         [57, 43, 52,  ..., 58, 46, 43],\n",
       "         [ 1, 47, 51,  ..., 42, 43, 52],\n",
       "         ...,\n",
       "         [40, 59, 58,  ..., 52, 43, 61],\n",
       "         [58,  1, 58,  ..., 50, 43,  8],\n",
       "         [58, 46, 47,  ..., 39, 58,  1]]),\n",
       " tensor([[27, 28, 10,  ..., 43, 52,  1],\n",
       "         [43, 52, 42,  ..., 46, 43,  1],\n",
       "         [47, 51, 54,  ..., 43, 52, 58],\n",
       "         ...,\n",
       "         [59, 58,  1,  ..., 43, 61,  1],\n",
       "         [ 1, 58, 47,  ..., 43,  8,  1],\n",
       "         [46, 47, 57,  ..., 58,  1, 16]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(torch.nn.Module):\n",
    "    def __init__(self, input_size, head_size):\n",
    "        super().__init__()\n",
    "        self.key = torch.nn.Linear(input_size, head_size)\n",
    "        self.query = torch.nn.Linear(input_size, head_size)\n",
    "        self.value = torch.nn.Linear(input_size, head_size)\n",
    "        self.register_buffer('mask', torch.tril(torch.ones(block_size, block_size)) == 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        v = self.value(x)\n",
    "        wei = q @ k.transpose(-2, -1) * (head_size**-0.5)\n",
    "        wei = wei.masked_fill(self.mask[:T, :T], float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        return wei @ v        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, n_heads, head_size, input_size):\n",
    "        super().__init__()\n",
    "        self.heads = torch.nn.ModuleList([Head(input_size, head_size) for _ in range(n_heads)])\n",
    "        self.proj = torch.nn.Linear(n_heads*head_size, input_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        x = self.proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(torch.nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(n_embd, 4 * n_embd),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(4 * n_embd, n_embd)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(torch.nn.Module):\n",
    "    def __init__(self, n_embd, n_heads):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_heads\n",
    "        self.sa = MultiHeadAttention(n_heads, head_size, n_embd)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = torch.nn.LayerNorm(n_embd)\n",
    "        self.ln2 = torch.nn.LayerNorm(n_embd)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.token_embedding_table = torch.nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = torch.nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = torch.nn.Sequential(\n",
    "            Block(n_embd, 4),\n",
    "            Block(n_embd, 4),\n",
    "            Block(n_embd, 4),\n",
    "            torch.nn.LayerNorm(n_embd)\n",
    "        )\n",
    "        self.lm_head = torch.nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=idx.device))\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.blocks(x)\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for i in range(max_new_tokens):\n",
    "            logits, _ = self(idx[:, -block_size:])\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            new_token = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat([idx, new_token], dim=-1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = Model().to(device)\n",
    "optimizer = torch.optim.AdamW(lm.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss 4.653528213500977\n",
      "step 100, loss 2.597411632537842\n",
      "step 200, loss 2.380962610244751\n",
      "step 300, loss 2.2899081707000732\n",
      "step 400, loss 2.1950089931488037\n",
      "step 500, loss 2.149674892425537\n",
      "step 600, loss 2.1492626667022705\n",
      "step 700, loss 2.097557544708252\n",
      "step 800, loss 2.0751748085021973\n",
      "step 900, loss 2.0033926963806152\n",
      "step 1000, loss 1.9987818002700806\n",
      "step 1100, loss 1.9997889995574951\n",
      "step 1200, loss 1.9755010604858398\n",
      "step 1300, loss 1.9807460308074951\n",
      "step 1400, loss 1.9936994314193726\n",
      "step 1500, loss 1.951111078262329\n",
      "step 1600, loss 1.965682029724121\n",
      "step 1700, loss 1.9140479564666748\n",
      "step 1800, loss 1.976563811302185\n",
      "step 1900, loss 1.9149105548858643\n",
      "step 2000, loss 1.9191391468048096\n",
      "step 2100, loss 1.9168260097503662\n",
      "step 2200, loss 1.8981072902679443\n",
      "step 2300, loss 1.9315135478973389\n",
      "step 2400, loss 1.8563764095306396\n",
      "step 2500, loss 1.8911774158477783\n",
      "step 2600, loss 1.876099944114685\n",
      "step 2700, loss 1.880812644958496\n",
      "step 2800, loss 1.875939130783081\n",
      "step 2900, loss 1.8704488277435303\n",
      "step 3000, loss 1.8358409404754639\n",
      "step 3100, loss 1.8267815113067627\n",
      "step 3200, loss 1.8583399057388306\n",
      "step 3300, loss 1.8676506280899048\n",
      "step 3400, loss 1.871495246887207\n",
      "step 3500, loss 1.8369029760360718\n",
      "step 3600, loss 1.8251430988311768\n",
      "step 3700, loss 1.806637167930603\n",
      "step 3800, loss 1.8689918518066406\n",
      "step 3900, loss 1.8443105220794678\n",
      "step 4000, loss 1.8446705341339111\n",
      "step 4100, loss 1.7956081628799438\n",
      "step 4200, loss 1.811532735824585\n",
      "step 4300, loss 1.8150265216827393\n",
      "step 4400, loss 1.8094545602798462\n",
      "step 4500, loss 1.7848869562149048\n",
      "step 4600, loss 1.7931115627288818\n",
      "step 4700, loss 1.8136717081069946\n",
      "step 4800, loss 1.8164253234863281\n",
      "step 4900, loss 1.8161081075668335\n"
     ]
    }
   ],
   "source": [
    "for step in range(5000):\n",
    "    x, y = get_batch('train')\n",
    "    logits, loss = lm(x, y)\n",
    "    if step % 100 == 0:\n",
    "        print(f'step {step}, loss {loss.item()}')\n",
    "    lm.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BENVOLIO:\n",
      "He unk of Rarrand,\n",
      "That tere beseep's of good father; the long-ate a woman him;\n",
      "pounter's of in 'Ther him!\n",
      "To this by where weeth his scow shut this belse part,\n",
      "Have my spain,\n",
      "faumel reman:\n",
      "He him,\n",
      "We as think die in him.\n",
      "\n",
      "POMPEY:\n",
      "When war?\n",
      "\n",
      "ISABELLA:\n",
      "That is,\n",
      "To himself are ocley'd fear you hate faulted and with to gentleman:\n",
      "This one what the down it,\n",
      "Age mad is what numechanns of sorrow thous' they flown's mishes the cannori, I shall them wit,\n",
      "There shade per:\n",
      "Servess a back good on thus: how it in thee he bows his content. I draw are are farew thee: other\n",
      "My four tone,\n",
      "Make old escome the lak:\n",
      "Ah, commarch'd Goding Mypearius.\n",
      "\n",
      "LADY CAPULET:\n",
      "We have day must-atter you.\n",
      "What I we the down the And fear it to did me, love an thy hach curta is are his by count and my he' sweek heaven,\n",
      "And by come me, and since with corsciolane hadst,\n",
      "I secross nots,\n",
      "If this, put unfan so day.\n",
      "\n",
      "ROMNGHPEY:\n",
      "\n",
      "ESCALUS:\n",
      "The braise with not this,\n",
      "In yours:\n",
      "That not is the kingness a to winder:\n",
      "She, y\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros((1, 1), dtype=torch.int64).to(device)\n",
    "y_ = lm.generate(x, 1000)\n",
    "print(decode(y_[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi More's are of Romeo and made yo\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([encode('Hi M')]).to(device)\n",
    "y_ = lm.generate(x, 30)\n",
    "print(decode(y_[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
